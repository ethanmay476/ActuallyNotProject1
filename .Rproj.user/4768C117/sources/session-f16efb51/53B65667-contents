---
title: "Final Project"
author: "Ethan May"
output: pdf_document
date: "2023-12-10"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
<em> DATA EVALUATION</em>

The data set that will be analysed in this essay serves the purpose of helping detect heart disease in its early stages. Cardiovascular diseases according to the World Health Organization (WHO) are currently the leading causes of death globally. CVDs encompass all diseases/conditions that affect the heart such as, coronary artery disease, heart failures, and strokes. The goal of analyzing Cardiovascular disease data will be to create models that can help predict these diseases in its early stages. 

The data set being analysed in this essay covers 1000 patients from a multispecialty hospital in Indiana. There are 14 different variables within this data 12 will be used as predictor variables and 1 will be used as the response variable. The response variable is called "target". This variable is binary, where a '0' indicates that the patient is free from and heart disease and '1' indicates that the patient has heart disease. Of the other 13 variables 1 contains the patient ID, this variable has no influence on the target so it will not be used. Then the other 12 are a mix of categorical and numerical variables that are all predictors of the response variable. **Table 1** contains an overview of the different types of data used in the data set. 

As seen in the table there are 7 different Numerical variables. The seven numerical variables are: patientid(which will not be used within the the models), age (In years), restingBP(patients  resting blood pressure 94-200 in mm HG), serumcholestrol(patients cholesterol levels 126-564 in ml/dl), maxheartrate(patients maximum heart rate 71-202), oldpeak(this is a measure of a specific electrical signal the heart produces 0-6.2) and noofmajorvessesl(Number of major blood vessles with defects 0-3).  

The 7 Categorical Variables are: Gender, fastingbloodsugar(this is a blood test, 1 means patient has a test > 120mg/dl meaning they have either prediabetes or diabetes, 0 then means this is under 120mg/dl), chestpain(0 being typical angina chest pain, 1 being atypical, 2 being non-aginal pain, and 3 being no symptoms), restingrelectro(results of a electrocardiogram test, 0 being normal, 1 being ST-T abnormal, and 2 being probable or definite left ventricular hypertrophy), exercuseangia(1 being this person experiences chest pain when exercising, 0 being no pain),slope (slope of ST segment during exercise, 1 being upslope, 2 being flat, and 3 being down slope), and then target which is the response variable that was mentioned before.

<em> EXPLANITORY ANALYSIS</em>


**Graph 1** is a boxplot of our response variable. From this boxplot we can see that there is some imbalance of the target variable. This could lead to some bias within the models that we make. Overall there is no extreme imbalance in this data set so the bias should be minimal.

**Graph 2** is another boxplot that shows the distribution between male and females. From this plot we can gather that there are is a significantly higher number of men than woman. **Table 2** then shows that from this data set males are more likely to have heart disease.

**Graph 3** shows the distribution between age and whether or not the patient has heart disease. From these results we see that from ages 20-25 most of the patients do not have any heart disease, but from ages 25-75 the majority of patients do have heart disease and for 75+ the split is fairly even.

**Graph 4** shows the distribution of heart pain by heart disease. This graph shows that for those with typical angina chest pain the majority does not have heart Disease. And then for those with atypical angina chest pain and non-aginal pain, the majority has heart disease. And interstingly almost every patient with no symptoms has heart disease. This is likely because every object in this data set is coming from a hospital. 

**Graph 5** shows the relationship between resting blood pressure and those who have heart disease. From this graph we see on average those who have heart disease have a higher resting blood pressure. 

**Graph 6** shows the relationship between the patients cholesterol levels and who has heart disease. From the graph we see that on average those who have heart disease have higher cholesterol levels.

**Graph 7** shows the relationship between the blood sugar test and those who have heart disease. This graph found that those who have a blood sugar > than 120mg/dl are more likely to have cardiovascular disease than those who have a blood sugar < 120mg/dl.

**Graph 8** shows the relationship between electrocardiogram test results and heart disease. This graph finds that those who probable or definite left ventricular hypertrophy, are the most likely to have heart disease, while those being ST-T abnormal are also more likely to have heart disease than those with normal results.

**Graph 9** shows the relationship between a patients max heart rate and the likelihood they have a heart disease. This graph finds that those with higher max heart rates are more likely to have heart disease.

**Graph 10** shows the relationship between chest pain caused by exercise and the likelihood that the patient has a heart disease. This Graph found little to no correlation between this kind of chest pain and heart disease.

**Graph 11** shows the relationship between oldpeak levels and the likelihood a patient has heart disease. This graph find that higher oldpeak levels means an increased likelihood of heart disease.

**Graph 12** shows the relationship between the slope of a patient ST-T and the likelihood this patient has a heart disease. The graph shows a strong correlation between the slope and this likely hood. Patients with an upslope are unlikely to have heart disease, patients with a flat slope are likely to have heart disease, and patients with a down slope are guaranteed to have heart disease.

**Graph 13** shows the relationship between the number of major blood vessels a patient has and the likelihood this patient has a heart disease. This graph shows that patients with 0 major blood vessel defects are unlikely to have heart disease, while those with 1-3 are likely to have heart disease.


<em> MODELING AND ANALYSIS/INTERPRETATIONS </em>

**Decision Tree**

The first method we are going to use to create a model for this data is a decision tree. One of the strengths of a decision tree that makes it suitable for this data set is how decision trees handle categorical variables with ease. They are also easily interpretable as how the model makes decisions is made clear. The response variable in this case is a binary variable, meaning that the model used must be effective when it comes to binary classification problems. Decision trees are effective at these types of problems.

One potential draw back that will have to be accounted for is that decision trees are prone to over fitting. One way to counter act over fitting is through pruning which will be done for this model.

For this tree a 80% training set and 20% test set was used.

The first tree produced has an accuracy of 0.9695122 and the confusion matrix produced shows that 47 instances were correctly predicted in the negative class, 112 were correctly predicted in the positive class, 4 were a false negative and 1 was a false positive.

These results clearly show that this tree is a good fit, but due to the high likelihood of over fitting pruning was applied to this tree to prevent this.

To prune the tree 10-fold cross validation was run on the original tree. This cross validation found that the best cp value for the pruned tree was 0.04166667.

The pruned trees accuracy is 0.9634146 and the confusion matrix shows 46 instances were correctly predicted in the negative class, 112 were correctly predicted in the positive class, 4 were a false negative and 2 were a false positive.

This pruned tree is a good fit for the data and the risk of over fitting is much lower.

The root node of this decision tree is the variable slope. The pruned tree splits at slope so the value 1 goes to the left and the values 2 and 3 go to the right. The right values automatically are given the target value 1 meaning that that patient is predicted to have heart disease.

The next node on the left side is restingBp, here if the value is less than 157 the patient is not predicted to have heart disease and if it is equal or greater than 157 then we go to the next node.

The next node is oldpeak. If the oldpeak value is greater than or equal to 2.5 than the patient is not predicted to have heart disease otherwise they are predicted to have heart disease.

**Random Forest**

The next method that was used to create a model for this data is a random forest. Random forests are effective at predicting with high accuracy with a low chance at over fitting. The reason that random forests have a low chance at over fitting is because they average predictions from a high number of trees. The same reasons regarding binary classification that made the decision tree so effective also makes the Random forest effective.

The random forest also used a 80% training set and 20% test set.
The random forest produced used 500 trees with a maximum depth of 10.

The random forest model has an accuracy of 0.9939024 and its confusion matrix shows 47 instances were correctly predicted in the negative class, 116 were correctly predicted in the positive class, and 1 was a false positive.

The random forest model is a very good fit that also has a low chance of being over fitted.

The **ROC Curve** produced shows that that predictions are near 100% correct

**KNN**

The final method used to create a model for this data was k nearest neighbors. One of the advantages K nearest neighbor models is that they can be effective in situations where some data is imbalanced. In this case as we saw before there is an uneven distribution in the target variable where there are more patients with heart disease then without. This Knn model should be able to create a good model despite this. Another advantage of Knn models is that they are very simple and flexible. This model is significantly less complicated than the Random Forest model.

This model like the previous is using a split of an 80% training set and an 20% test set.

10-fold cross validation was used in the creation of this model as well.
The Knn model produced an accuracy of 0.8292683 and the confusion matrix shows 31 instances were correctly predicted in the negative class, 105 were correctly predicted in the positive class, and 17 were a false positive and 11 were a false negative.

This model is a good fit and likely is not over or under fit, however the models effectiveness is not as good as either the decision tree or the random forest


<em> CONCLUSIONS </em>
From analyzing this data it can be seen what the best indicators of heart disease can be. 
From the decision tree we see that the most important indicators are slope,restingBP,chestpain,noofmajorvessels,maxheartrate,oldpeak, and restingrelectro. 
From the using the Random forest model we could create predictions with an accuracy of 99%. There may still be a chance of overfitting with an accuracy this high, but because 500 trees were used the chance of overfitting was lowered.
The Knn model did not produce the same levels of accuracy of either of the other models but we can be confident that there is no overfitting with this model.
The biggest issue comes with the nature of the dataset being unbalanced. A more balanced data set with more observations would create models that would better predict heart disease. These models would work well in predicting whether a patient at a hospital has heart disease but chances are this would not work nearly as well for a random person. Overall this data was useful in showing the best predictors for heart disease.


```{r,echo=FALSE,results='hide',message=FALSE,warning=FALSE}
library(glmnet)
library(dplyr)
library(gt)
library(ggplot2)
library(tree)
library(caret)
library(rpart)
library(randomForest)
library(pROC)
library(boot)
library(rattle)
library(RColorBrewer)

library(rpart.plot)

```



```{r,echo=FALSE}
# Get dataset
Cardiovascular <- read.csv("C:\\Users\\Ethan May\\Documents\\STA 478\\Final Project\\Cardiovascular_Disease_Dataset.csv",header = TRUE)
Cardiovascular <- na.omit(Cardiovascular) # make sure no NA
# make gender var categorical
Cardiovascular$gender <- factor(Cardiovascular$gender, levels = c(0, 1), labels = c("Female", "Male"))
#make fasting blood sugar categorical
Cardiovascular$fastingbloodsugar <- factor(Cardiovascular$fastingbloodsugar, levels = c(0,1))
# make chestpain categorical
Cardiovascular$chestpain <- factor(Cardiovascular$chestpain, levels = c(0,1,2,3))
# make restingelect categorical
Cardiovascular$restingrelectro <- factor(Cardiovascular$restingrelectro, levels = c(0,1,2))
# make exciseangia categorical
Cardiovascular$exerciseangia <- factor(Cardiovascular$exerciseangia , levels = c(0,1))
# make slope categorical
Cardiovascular$slope <- factor(Cardiovascular$slope, levels = c(1,2,3))
# make target categorical
Cardiovascular$target <- factor(Cardiovascular$target, levels = c(0,1))

Cardiovascular_no_ID <- subset(Cardiovascular, select = -patientid) # create a df with no id var
Cardiovascular_no_ID <- na.omit(Cardiovascular_no_ID)

```


```{r,echo=FALSE}
#create table using gt() for an overview of the data
data_overview <- Cardiovascular %>%
  summarize(
    Number_of_Observations = n(),
    Number_of_Variables = ncol(.),
    Numeric_Variables = sum(sapply(., is.numeric)),
    Categorical_Variables = sum(sapply(., is.factor))
  ) %>%
  gt() %>%
  tab_header(
    title = "Table 1",
    subtitle = "Data Overview"
  ) %>%
  fmt_number(
    columns = c(Number_of_Observations, Number_of_Variables, Numeric_Variables, Categorical_Variables),
    decimals = 0)
data_overview
#create barplot
barplot(table(Cardiovascular_no_ID$target),col = c("lightblue", "orange"), main = "Graph 1", sub = "Presence of Heart Disease", legend.text = TRUE,names.arg = c("No Heart Disease", "Heart Disease"))

#create barplot

barplot(table(Cardiovascular_no_ID$gender),col = c("lightblue", "orange"), main = "Graph 2", sub = "Gender Distribution" , legend.text = TRUE,names.arg = c("No Female", "Male"))

# get percentage for gender and use gt() to make a table
percentage_HD_gender <- Cardiovascular_no_ID %>%
  group_by(gender) %>%
  summarise(Percentage = mean(target == '1') * 100)


table2 <- percentage_HD_gender %>%
  gt() %>%
  tab_header(
    title = "Table 2",
    subtitle = "Percentage of Heart Disease by Gender"
  ) %>%
  fmt_number(
    columns = c(Percentage),
    decimals = 1
  ) %>%
  tab_spanner(
    label = "",
    columns = c(Percentage)
  )
table2



# create histogram for age
ggplot(Cardiovascular_no_ID, aes(x = age, fill = factor(target))) +
  geom_histogram(binwidth = 10, position = "identity", alpha = 0.7) +
  labs(title = "Graph 3", subtitle = "Distribution of Age by Heart Disease",
       x = "Age",
       y = "Frequency") +
  scale_fill_manual(values = c("orange", "lightblue"), name = "Heart Disease") +
  theme_minimal()


# create bar for chestpain
ggplot(Cardiovascular_no_ID, aes(x = chestpain, fill = factor(target))) +
  geom_bar(position = "dodge", alpha = 0.7) +
  labs(title = "Graph 4", subtitle = "Distribution of Chest Pain by Heart Disease",
       x = "Chest Pain",
       y = "Count") +
  scale_fill_manual(values = c("lightblue", "orange"), name = "Heart Disease") +
  theme_minimal()




# create boxplot for resting bp
ggplot(Cardiovascular_no_ID, aes(x = factor(target), y = restingBP, fill = factor(target))) +
  geom_boxplot(alpha = 0.7) +
  geom_jitter(position = position_jitter(width = 0.2), alpha = 0.5) +
  labs(title = "Graph 5", subtitle = "Comparison of Resting Blood Pressure by Heart Disease",
       x = "Heart Disease",
       y = "Resting Blood Pressure") +
  scale_fill_manual(values = c("lightblue", "orange"), name = "Heart Disease") +
  theme_minimal()


# create boxplot for serumcholestrol
ggplot(Cardiovascular_no_ID, aes(x = factor(target), y = serumcholestrol, fill = factor(target))) +
  geom_boxplot(alpha = 0.7) +
  geom_jitter(position = position_jitter(width = 0.2), alpha = 0.5) +
  labs(title = "Graph 6", subtitle = "Comparison of Cholestrol by Heart Disease",
       x = "Heart Disease",
       y = "Serum Cholestrol") +
  scale_fill_manual(values = c("lightblue", "orange"), name = "Heart Disease") +
  theme_minimal()



# create bar for fastingbloodsugar
ggplot(Cardiovascular_no_ID, aes(x = fastingbloodsugar, fill = factor(target))) +
  geom_bar(position = "dodge", alpha = 0.7) +
  labs(title = "Graph 7", subtitle = "Fasting blood sugar test results by Heart Disease",
       x = "Heart Disease",
       y = "Blood Sugar > 120mg/dl") +
  scale_fill_manual(values = c("lightblue", "orange"), name = "Heart Disease") +
  theme_minimal()



# create bar for resting electro
ggplot(Cardiovascular_no_ID, aes(x = restingrelectro, fill = factor(target))) +
  geom_bar(position = "dodge", alpha = 0.7) +
  labs(title = "Graph 8", subtitle = "Resting electrocardiogram results by Heart Disease",
       x = "Heart Disease",
       y = "electrocardiogram resultsl") +
  scale_fill_manual(values = c("lightblue", "orange"), name = "Heart Disease") +
  theme_minimal()

# create box plot for max heart rate
ggplot(Cardiovascular_no_ID, aes(x = factor(target), y = maxheartrate, fill = factor(target))) +
  geom_boxplot(alpha = 0.7) +
  geom_jitter(position = position_jitter(width = 0.2), alpha = 0.5) +
  labs(title = "Graph 9", subtitle = "Comparison of max heart rate by Heart Disease",
       x = "Heart Disease",
       y = "Max Heart Rate") +
  scale_fill_manual(values = c("lightblue", "orange"), name = "Heart Disease") +
  theme_minimal()

# create bar for angia
ggplot(Cardiovascular_no_ID, aes(x = exerciseangia, fill = factor(target))) +
  geom_bar(position = "dodge", alpha = 0.7) +
  labs(title = "Graph 10", subtitle = "Chest pain with exercise results by Heart Disease",
       x = "Heart Disease",
       y = "Chest pain with exercise") +
  scale_fill_manual(values = c("lightblue", "orange"), name = "Heart Disease") +
  theme_minimal()

# create box for oldpeak
ggplot(Cardiovascular_no_ID, aes(x = factor(target), y = oldpeak, fill = factor(target))) +
  geom_boxplot(alpha = 0.7) +
  geom_jitter(position = position_jitter(width = 0.2), alpha = 0.5) +
  labs(title = "Graph 11", subtitle = "Comparison of oldpeak and Heart Disease",
       x = "Heart Disease",
       y = "oldpeak") +
  scale_fill_manual(values = c("lightblue", "orange"), name = "Heart Disease") +
  theme_minimal()


# create bar for slope
ggplot(Cardiovascular_no_ID, aes(x = slope, fill = factor(target))) +
  geom_bar(position = "dodge", alpha = 0.7) +
  labs(title = "Graph 12", subtitle = "slope of ST vs Heart Disease",
       x = "Heart Disease",
       y = "slope of ST") +
  scale_fill_manual(values = c("lightblue", "orange"), name = "Heart Disease") +
  theme_minimal()

# craete bar for noofmajorvessles
ggplot(Cardiovascular_no_ID, aes(x = noofmajorvessels, fill = factor(target))) +
  geom_bar(position = "dodge", alpha = 0.7) +
  labs(title = "Graph 13", subtitle = "Number of major blood vessels vs Heart Disease",
       x = "Heart Disease",
       y = "Number of Major Vessels") +
  scale_fill_manual(values = c("lightblue", "orange"), name = "Heart Disease") +
  theme_minimal()
```

```{r,echo=FALSE}

set.seed(1)
  train <- createDataPartition(Cardiovascular_no_ID$target, p = 0.8, list = FALSE) #create training partition
  
  training_set <- Cardiovascular_no_ID[train, ] #create training set
  
  
  test_set <- Cardiovascular_no_ID[-train, ] # create validation set

tree <- rpart(target ~ ., data = training_set, method = "class") # create tree model


fancyRpartPlot(tree,caption  = "DecisionTree")  # plot the tree

predictions <- predict(tree, newdata = test_set, type = "class") # create prediction
accuracy <- mean(predictions == test_set$target) # test accuracy
accuracy


conf_matrix <- table(Actual = test_set$target, Predicted = predictions) # make conf matrix to test model

print(conf_matrix)





```


```{r,echo=FALSE}
set.seed(1)
cv_results <- train(
  target ~ .,
  data = Cardiovascular_no_ID,
  method = "rpart",
  trControl = trainControl(method = "cv", number = 10)
) # cross validation for prune
cv_results$bestTune$cp
pruned_tree <- prune(tree, cp = cv_results$bestTune$cp) # prune thre tree
fancyRpartPlot(pruned_tree,caption = "Pruned Tree")



predictions <- predict(pruned_tree, newdata = test_set, type = "class") # create prediction
accuracy <- mean(predictions == test_set$target) # test accuracy
accuracy


conf_matrix <- table(Actual = test_set$target, Predicted = predictions) # make conf matrix to test model
print(conf_matrix)
```



```{r, echo = FALSE}
target_variable <- "target"
features <- setdiff(names(training_set), target_variable)

#Random Forest model
rf_model <- randomForest(
  x = training_set[, features],
  y = training_set[, target_variable],
  ntree = 500,  # Number of trees in the forest 
  mtry = sqrt(length(features)),  
  importance = TRUE,  # Compute feature importance
    max_depth = 10 

)
predictions <- predict(rf_model, newdata = test_set[, features]) # get predictions

confusion_matrix <- table(Actual = test_set$target, Predicted = predictions) # get conf matrix
print(confusion_matrix)

# Compute accuracy
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
accuracy

roc_curve <- roc(test_set$target, as.numeric(predictions))
plot(roc_curve, col = "blue", main = "ROC Curve")
roc_curve$auc
```

```{r, echo=FALSE}
set.seed(1)
  train <- createDataPartition(Cardiovascular_no_ID$target, p = 0.8, list = FALSE) #create training partition
  
  training_set <- Cardiovascular_no_ID[train, ] #create training set
  
  
  test_set <- Cardiovascular_no_ID[-train, ] # create validation set
# define the 10-fold cv
ctrl <- trainControl(method = "cv", number = 10)
# run knn with cv 10 fold
model <- train(target ~ ., data = training_set, method = "knn", trControl = ctrl)


predictions <- predict(model, newdata = test_set)
accuracy <- mean(predictions == test_set$target) # test accuracy
accuracy


conf_matrix <- table(Actual = test_set$target, Predicted = predictions) # make conf matrix to test model
print(conf_matrix)


```

```{r, echo=FALSE}
# decision tree summary

"**Summary of pruned decision tree**"

summary(pruned_tree)

# random forest summary

"**Summary of Random Forest**"

summary(rf_model)

# knn summary
"**Summary of 10-fold cross validated knn model**"

summary(model)
```



**Citations**

https://www.kaggle.com/datasets/jocelyndumlao/cardiovascular-disease-dataset

**Appendix**
library(glmnet)
library(dplyr)
library(gt)
library(ggplot2)
library(tree)
library(caret)
library(rpart)
library(randomForest)
library(pROC)
library(boot)
library(rattle)
library(RColorBrewer)

library(rpart.plot)



# Get dataset
Cardiovascular <- read.csv("C:\\Users\\Ethan May\\Documents\\STA 478\\Final Project\\Cardiovascular_Disease_Dataset.csv",header = TRUE)
Cardiovascular <- na.omit(Cardiovascular) # make sure no NA
# make gender var categorical
Cardiovascular$gender <- factor(Cardiovascular$gender, levels = c(0, 1), labels = c("Female", "Male"))
#make fasting blood sugar categorical
Cardiovascular$fastingbloodsugar <- factor(Cardiovascular$fastingbloodsugar, levels = c(0,1))
# make chestpain categorical
Cardiovascular$chestpain <- factor(Cardiovascular$chestpain, levels = c(0,1,2,3))
# make restingelect categorical
Cardiovascular$restingrelectro <- factor(Cardiovascular$restingrelectro, levels = c(0,1,2))
# make exciseangia categorical
Cardiovascular$exerciseangia <- factor(Cardiovascular$exerciseangia , levels = c(0,1))
# make slope categorical
Cardiovascular$slope <- factor(Cardiovascular$slope, levels = c(1,2,3))
# make target categorical
Cardiovascular$target <- factor(Cardiovascular$target, levels = c(0,1))

Cardiovascular_no_ID <- subset(Cardiovascular, select = -patientid) # create a df with no id var
Cardiovascular_no_ID <- na.omit(Cardiovascular_no_ID)

#create table using gt() for an overview of the data
data_overview <- Cardiovascular %>%
  summarize(
    Number_of_Observations = n(),
    Number_of_Variables = ncol(.),
    Numeric_Variables = sum(sapply(., is.numeric)),
    Categorical_Variables = sum(sapply(., is.factor))
  ) %>%
  gt() %>%
  tab_header(
    title = "Table 1",
    subtitle = "Data Overview"
  ) %>%
  fmt_number(
    columns = c(Number_of_Observations, Number_of_Variables, Numeric_Variables, Categorical_Variables),
    decimals = 0)
data_overview
#create barplot
barplot(table(Cardiovascular_no_ID$target),col = c("lightblue", "orange"), main = "Graph 1", sub = "Presence of Heart Disease", legend.text = TRUE,names.arg = c("No Heart Disease", "Heart Disease"))

#create barplot

barplot(table(Cardiovascular_no_ID$gender),col = c("lightblue", "orange"), main = "Graph 2", sub = "Gender Distribution" , legend.text = TRUE,names.arg = c("No Female", "Male"))

# get percentage for gender and use gt() to make a table
percentage_HD_gender <- Cardiovascular_no_ID %>%
  group_by(gender) %>%
  summarise(Percentage = mean(target == '1') * 100)


table2 <- percentage_HD_gender %>%
  gt() %>%
  tab_header(
    title = "Table 2",
    subtitle = "Percentage of Heart Disease by Gender"
  ) %>%
  fmt_number(
    columns = c(Percentage),
    decimals = 1
  ) %>%
  tab_spanner(
    label = "",
    columns = c(Percentage)
  )
table2



# create histogram for age
ggplot(Cardiovascular_no_ID, aes(x = age, fill = factor(target))) +
  geom_histogram(binwidth = 10, position = "identity", alpha = 0.7) +
  labs(title = "Graph 3", subtitle = "Distribution of Age by Heart Disease",
       x = "Age",
       y = "Frequency") +
  scale_fill_manual(values = c("orange", "lightblue"), name = "Heart Disease") +
  theme_minimal()


# create bar for chestpain
ggplot(Cardiovascular_no_ID, aes(x = chestpain, fill = factor(target))) +
  geom_bar(position = "dodge", alpha = 0.7) +
  labs(title = "Graph 4", subtitle = "Distribution of Chest Pain by Heart Disease",
       x = "Chest Pain",
       y = "Count") +
  scale_fill_manual(values = c("lightblue", "orange"), name = "Heart Disease") +
  theme_minimal()




# create boxplot for resting bp
ggplot(Cardiovascular_no_ID, aes(x = factor(target), y = restingBP, fill = factor(target))) +
  geom_boxplot(alpha = 0.7) +
  geom_jitter(position = position_jitter(width = 0.2), alpha = 0.5) +
  labs(title = "Graph 5", subtitle = "Comparison of Resting Blood Pressure by Heart Disease",
       x = "Heart Disease",
       y = "Resting Blood Pressure") +
  scale_fill_manual(values = c("lightblue", "orange"), name = "Heart Disease") +
  theme_minimal()


# create boxplot for serumcholestrol
ggplot(Cardiovascular_no_ID, aes(x = factor(target), y = serumcholestrol, fill = factor(target))) +
  geom_boxplot(alpha = 0.7) +
  geom_jitter(position = position_jitter(width = 0.2), alpha = 0.5) +
  labs(title = "Graph 6", subtitle = "Comparison of Cholestrol by Heart Disease",
       x = "Heart Disease",
       y = "Serum Cholestrol") +
  scale_fill_manual(values = c("lightblue", "orange"), name = "Heart Disease") +
  theme_minimal()



# create bar for fastingbloodsugar
ggplot(Cardiovascular_no_ID, aes(x = fastingbloodsugar, fill = factor(target))) +
  geom_bar(position = "dodge", alpha = 0.7) +
  labs(title = "Graph 7", subtitle = "Fasting blood sugar test results by Heart Disease",
       x = "Heart Disease",
       y = "Blood Sugar > 120mg/dl") +
  scale_fill_manual(values = c("lightblue", "orange"), name = "Heart Disease") +
  theme_minimal()



# create bar for resting electro
ggplot(Cardiovascular_no_ID, aes(x = restingrelectro, fill = factor(target))) +
  geom_bar(position = "dodge", alpha = 0.7) +
  labs(title = "Graph 8", subtitle = "Resting electrocardiogram results by Heart Disease",
       x = "Heart Disease",
       y = "electrocardiogram resultsl") +
  scale_fill_manual(values = c("lightblue", "orange"), name = "Heart Disease") +
  theme_minimal()

# create box plot for max heart rate
ggplot(Cardiovascular_no_ID, aes(x = factor(target), y = maxheartrate, fill = factor(target))) +
  geom_boxplot(alpha = 0.7) +
  geom_jitter(position = position_jitter(width = 0.2), alpha = 0.5) +
  labs(title = "Graph 9", subtitle = "Comparison of max heart rate by Heart Disease",
       x = "Heart Disease",
       y = "Max Heart Rate") +
  scale_fill_manual(values = c("lightblue", "orange"), name = "Heart Disease") +
  theme_minimal()

# create bar for angia
ggplot(Cardiovascular_no_ID, aes(x = exerciseangia, fill = factor(target))) +
  geom_bar(position = "dodge", alpha = 0.7) +
  labs(title = "Graph 10", subtitle = "Chest pain with exercise results by Heart Disease",
       x = "Heart Disease",
       y = "Chest pain with exercise") +
  scale_fill_manual(values = c("lightblue", "orange"), name = "Heart Disease") +
  theme_minimal()

# create box for oldpeak
ggplot(Cardiovascular_no_ID, aes(x = factor(target), y = oldpeak, fill = factor(target))) +
  geom_boxplot(alpha = 0.7) +
  geom_jitter(position = position_jitter(width = 0.2), alpha = 0.5) +
  labs(title = "Graph 11", subtitle = "Comparison of oldpeak and Heart Disease",
       x = "Heart Disease",
       y = "oldpeak") +
  scale_fill_manual(values = c("lightblue", "orange"), name = "Heart Disease") +
  theme_minimal()


# create bar for slope
ggplot(Cardiovascular_no_ID, aes(x = slope, fill = factor(target))) +
  geom_bar(position = "dodge", alpha = 0.7) +
  labs(title = "Graph 12", subtitle = "slope of ST vs Heart Disease",
       x = "Heart Disease",
       y = "slope of ST") +
  scale_fill_manual(values = c("lightblue", "orange"), name = "Heart Disease") +
  theme_minimal()

# craete bar for noofmajorvessles
ggplot(Cardiovascular_no_ID, aes(x = noofmajorvessels, fill = factor(target))) +
  geom_bar(position = "dodge", alpha = 0.7) +
  labs(title = "Graph 13", subtitle = "Number of major blood vessels vs Heart Disease",
       x = "Heart Disease",
       y = "Number of Major Vessels") +
  scale_fill_manual(values = c("lightblue", "orange"), name = "Heart Disease") +
  theme_minimal()

library(maptree)
set.seed(1)
  train <- createDataPartition(Cardiovascular_no_ID$target, p = 0.8, list = FALSE) #create training partition
  
  training_set <- Cardiovascular_no_ID[train, ] #create training set
  
  
  test_set <- Cardiovascular_no_ID[-train, ] # create validation set

tree <- rpart(target ~ ., data = training_set, method = "class") # create tree model


fancyRpartPlot(tree,caption  = "DecisionTree")  # plot the tree

predictions <- predict(tree, newdata = test_set, type = "class") # create prediction
accuracy <- mean(predictions == test_set$target) # test accuracy
accuracy


conf_matrix <- table(Actual = test_set$target, Predicted = predictions) # make conf matrix to test model

print(conf_matrix)

set.seed(1)
cv_results <- train(
  target ~ .,
  data = Cardiovascular_no_ID,
  method = "rpart",
  trControl = trainControl(method = "cv", number = 10)
) # cross validation for prune
cv_results$bestTune$cp
pruned_tree <- prune(tree, cp = cv_results$bestTune$cp) # prune thre tree
fancyRpartPlot(pruned_tree,caption = "Pruned Tree")



predictions <- predict(pruned_tree, newdata = test_set, type = "class") # create prediction
accuracy <- mean(predictions == test_set$target) # test accuracy
accuracy


conf_matrix <- table(Actual = test_set$target, Predicted = predictions) # make conf matrix to test model
print(conf_matrix)

target_variable <- "target"
features <- setdiff(names(training_set), target_variable)

#Random Forest model
rf_model <- randomForest(
  x = training_set[, features],
  y = training_set[, target_variable],
  ntree = 500,  # Number of trees in the forest 
  mtry = sqrt(length(features)),  
  importance = TRUE,  # Compute feature importance
    max_depth = 10 

)
predictions <- predict(rf_model, newdata = test_set[, features]) # get predictions

confusion_matrix <- table(Actual = test_set$target, Predicted = predictions) # get conf matrix
print(confusion_matrix)

# Compute accuracy
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
accuracy

roc_curve <- roc(test_set$target, as.numeric(predictions))
plot(roc_curve, col = "blue", main = "ROC Curve")
roc_curve$auc

set.seed(1)
  train <- createDataPartition(Cardiovascular_no_ID$target, p = 0.8, list = FALSE) #create training partition
  
  training_set <- Cardiovascular_no_ID[train, ] #create training set
  
  
  test_set <- Cardiovascular_no_ID[-train, ] # create validation set
# define the 10-fold cv
ctrl <- trainControl(method = "cv", number = 10)
# run knn with cv 10 fold
model <- train(target ~ ., data = training_set, method = "knn", trControl = ctrl)


predictions <- predict(model, newdata = test_set)
accuracy <- mean(predictions == test_set$target) # test accuracy
accuracy


conf_matrix <- table(Actual = test_set$target, Predicted = predictions) # make conf matrix to test model
print(conf_matrix)



# decision tree summary

"**Summary of pruned decision tree**"

summary(pruned_tree)

# random forest summary

"**Summary of Random Forest**"

summary(rf_model)

# knn summary
"**Summary of 10-fold cross validated knn model**"

summary(model)





